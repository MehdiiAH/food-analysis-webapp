{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8161a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c5b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_recipe = pd.read_csv(\"data/raw/RAW_recipes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391447a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autumn is my favorite time of year to cook! this recipe \n",
      "can be prepared either spicy or sweet, your choice!\n",
      "two of my posted mexican-inspired seasoning mix recipes are offered as suggestions.\n",
      "\n",
      "Tokens\n",
      "autumn autumn PROPN NNP nsubj is\n",
      "is be AUX VBZ ROOT is\n",
      "my my PRON PRP$ poss time\n",
      "favorite favorite ADJ JJ amod time\n",
      "time time NOUN NN attr is\n",
      "of of ADP IN prep time\n",
      "year year NOUN NN pobj of\n",
      "to to PART TO aux cook\n",
      "cook cook VERB VB relcl time\n",
      "! ! PUNCT . punct is\n",
      "this this DET DT det recipe\n",
      "recipe recipe NOUN NN nsubjpass prepared\n",
      "\n",
      " \n",
      " SPACE _SP dep recipe\n",
      "can can AUX MD aux prepared\n",
      "be be AUX VB auxpass prepared\n",
      "prepared prepare VERB VBN ROOT prepared\n",
      "either either CCONJ CC preconj spicy\n",
      "spicy spicy ADJ JJ dep prepared\n",
      "or or CCONJ CC cc spicy\n",
      "sweet sweet ADJ JJ conj spicy\n",
      ", , PUNCT , punct choice\n",
      "your your PRON PRP$ poss choice\n",
      "choice choice NOUN NN npadvmod prepared\n",
      "! ! PUNCT . punct prepared\n",
      "\n",
      " \n",
      " SPACE _SP dep !\n",
      "two two NUM CD nsubjpass offered\n",
      "of of ADP IN prep two\n",
      "my my PRON PRP$ poss recipes\n",
      "posted post VERB VBN amod recipes\n",
      "mexican mexican PROPN NNP npadvmod inspired\n",
      "- - PUNCT HYPH punct inspired\n",
      "inspired inspire VERB VBN amod recipes\n",
      "seasoning seasoning NOUN NN amod recipes\n",
      "mix mix NOUN NN compound recipes\n",
      "recipes recipe NOUN NNS pobj of\n",
      "are be AUX VBP auxpass offered\n",
      "offered offer VERB VBN ROOT offered\n",
      "as as ADP IN prep offered\n",
      "suggestions suggestion NOUN NNS pobj as\n",
      ". . PUNCT . punct offered\n",
      "\n",
      " Sentences\n",
      "autumn is my favorite time of year to cook!\n",
      "this recipe \n",
      "can be prepared either spicy or sweet, your choice!\n",
      "\n",
      "two of my posted mexican-inspired seasoning mix recipes are offered as suggestions.\n",
      "\n",
      " Chunks\n",
      "autumn → autumn\n",
      "my favorite time → time\n",
      "year → year\n",
      "this recipe → recipe\n",
      "my posted mexican-inspired seasoning mix recipes → recipes\n",
      "suggestions → suggestions\n",
      "\n",
      " Dependencies\n",
      "autumn     ←nsubj     – is\n",
      "is         ←ROOT      – is\n",
      "my         ←poss      – time\n",
      "favorite   ←amod      – time\n",
      "time       ←attr      – is\n",
      "of         ←prep      – time\n",
      "year       ←pobj      – of\n",
      "to         ←aux       – cook\n",
      "cook       ←relcl     – time\n",
      "!          ←punct     – is\n",
      "this       ←det       – recipe\n",
      "recipe     ←nsubjpass – prepared\n",
      "\n",
      "         ←dep       – recipe\n",
      "can        ←aux       – prepared\n",
      "be         ←auxpass   – prepared\n",
      "prepared   ←ROOT      – prepared\n",
      "either     ←preconj   – spicy\n",
      "spicy      ←dep       – prepared\n",
      "or         ←cc        – spicy\n",
      "sweet      ←conj      – spicy\n",
      ",          ←punct     – choice\n",
      "your       ←poss      – choice\n",
      "choice     ←npadvmod  – prepared\n",
      "!          ←punct     – prepared\n",
      "\n",
      "         ←dep       – !\n",
      "two        ←nsubjpass – offered\n",
      "of         ←prep      – two\n",
      "my         ←poss      – recipes\n",
      "posted     ←amod      – recipes\n",
      "mexican    ←npadvmod  – inspired\n",
      "-          ←punct     – inspired\n",
      "inspired   ←amod      – recipes\n",
      "seasoning  ←amod      – recipes\n",
      "mix        ←compound  – recipes\n",
      "recipes    ←pobj      – of\n",
      "are        ←auxpass   – offered\n",
      "offered    ←ROOT      – offered\n",
      "as         ←prep      – offered\n",
      "suggestions ←pobj      – as\n",
      ".          ←punct     – offered\n",
      "\n",
      " Pipeline\n",
      "tok2vec <class 'spacy.pipeline.tok2vec.Tok2Vec'>\n",
      "tagger <class 'spacy.pipeline.tagger.Tagger'>\n",
      "parser <class 'spacy.pipeline.dep_parser.DependencyParser'>\n",
      "attribute_ruler <class 'spacy.pipeline.attributeruler.AttributeRuler'>\n",
      "lemmatizer <class 'spacy.lang.en.lemmatizer.EnglishLemmatizer'>\n",
      "ner <class 'spacy.pipeline.ner.EntityRecognizer'>\n"
     ]
    }
   ],
   "source": [
    "data_recipe.head()\n",
    "data_text=data_recipe[['name','description']]\n",
    "data_text.head()\n",
    "\n",
    "doc=nlp(data_text['description'][0])\n",
    "\n",
    "print(doc)\n",
    "\n",
    "print(\"\\nTokens\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.head.text)\n",
    "\n",
    "print(\"\\n Sentences\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "\n",
    "print(\"\\n Chunks\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, \"→\", chunk.root.text)\n",
    "\n",
    "print(\"\\n Dependencies\")\n",
    "#spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<10} ←{token.dep_:<10}– {token.head.text}\")\n",
    "\n",
    "print(\"\\n Pipeline\")\n",
    "for name, component in nlp.pipeline:\n",
    "    print(name, type(component))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e1980",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlemmas\u001b[39m\u001b[33m\"\u001b[39m: lemmas,\n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnoun_chunks\u001b[39m\u001b[33m\"\u001b[39m: noun_chunks,\n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpos_counts\u001b[39m\u001b[33m\"\u001b[39m: pos_dict\n\u001b[32m     33\u001b[39m     }\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 🔹 Appliquer la fonction à chaque description\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m data_text[\u001b[33m\"\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdata_text\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 🔹 Si tu veux une seule liste fusionnée (par ex. pour vectorisation ultérieure)\u001b[39;00m\n\u001b[32m     39\u001b[39m data_text[\u001b[33m\"\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m\"\u001b[39m] = data_text[\u001b[33m\"\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mlemmas\u001b[39m\u001b[33m\"\u001b[39m] + x[\u001b[33m\"\u001b[39m\u001b[33mnoun_chunks\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_features\u001b[39m(text):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Exemple 1 : tous les lemmes significatifs (hors stop words, ponctuations)\u001b[39;00m\n\u001b[32m     19\u001b[39m     lemmas = [token.lemma_.lower() \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token.is_alpha \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.is_stop]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\spacy\\language.py:1053\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1051\u001b[39m     error_handler = proc.get_error_handler()\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     doc = \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E109.format(name=name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:121\u001b[39m, in \u001b[36mTok2Vec.predict\u001b[39m\u001b[34m(self, docs)\u001b[39m\n\u001b[32m    119\u001b[39m     width = \u001b[38;5;28mself\u001b[39m.model.get_dim(\u001b[33m\"\u001b[39m\u001b[33mnO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.model.ops.alloc((\u001b[32m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m tokvecs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:334\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) -> OutT:\n\u001b[32m    331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, Xseq, is_train)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.layers[\u001b[32m0\u001b[39m](Xseq, is_train)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[39m, in \u001b[36m_list_forward\u001b[39m\u001b[34m(model, Xs, is_train)\u001b[39m\n\u001b[32m     75\u001b[39m lengths = NUMPY_OPS.asarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[32m     76\u001b[39m Xf = layer.ops.flatten(Xs, pad=pad)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m Yf, get_dXf = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dYs: ListXd) -> ListXd:\n\u001b[32m     80\u001b[39m     dYf = layer.ops.flatten(dYs, pad=pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output + dX\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m Y, backprop_layer = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] + Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "    \u001b[31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\layernorm.py:24\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[InT, Callable]:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     N, mu, var = \u001b[43m_get_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     Xhat = (X - mu) * var ** (-\u001b[32m1.0\u001b[39m / \u001b[32m2.0\u001b[39m)\n\u001b[32m     26\u001b[39m     Y, backprop_rescale = _begin_update_scale_shift(model, Xhat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\thinc\\layers\\layernorm.py:75\u001b[39m, in \u001b[36m_get_moments\u001b[39m\u001b[34m(ops, X)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_moments\u001b[39m(ops: Ops, X: Floats2d) -> Tuple[Floats2d, Floats2d, Floats2d]:\n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# TODO: Do mean methods\u001b[39;00m\n\u001b[32m     74\u001b[39m     mu: Floats2d = X.mean(axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     var: Floats2d = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m + \u001b[32m1e-08\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Floats2d, ops.asarray_f([X.shape[\u001b[32m1\u001b[39m]])), mu, var\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\steph\\AI_Projects\\ProjetGroupeBigDataRecettes\\food-analysis-webapp\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:190\u001b[39m, in \u001b[36m_var\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    185\u001b[39m         arrmean = arrmean / rcount\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m x = asanyarray(arr - arrmean)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr.dtype.type, (nt.floating, nt.integer)):\n\u001b[32m    193\u001b[39m     x = um.multiply(x, x, out=x)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Charger modèle sans NER\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "# DataFrame avec texte\n",
    "# data_recipe = pd.read_csv(\"recipes.csv\")\n",
    "data_text = data_recipe[['name', 'description']].dropna()\n",
    "\n",
    "# Fonction optimisée (sans créer doc ici)\n",
    "def extract_features(doc):\n",
    "    lemmas = [t.lemma_.lower() for t in doc if t.is_alpha and t.text.lower() not in stopwords]\n",
    "    noun_chunks = [c.text.lower() for c in doc.noun_chunks]\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    pos_dict = {doc.vocab[i].text: count for i, count in pos_counts.items()}\n",
    "    return {\"lemmas\": lemmas, \"noun_chunks\": noun_chunks, \"pos_counts\": pos_dict}\n",
    "\n",
    "# Traitement par lots (streaming + multi-process)\n",
    "texts = data_text[\"description\"].tolist()\n",
    "features = []\n",
    "\n",
    "for doc in nlp.pipe(texts, batch_size=50, n_process=4):  # n_process = nb de CPU\n",
    "    features.append(extract_features(doc))\n",
    "\n",
    "# Assemblage\n",
    "data_text[\"features\"] = features\n",
    "data_text[\"tokens\"] = [f[\"lemmas\"] + f[\"noun_chunks\"] for f in features]\n",
    "\n",
    "# Export\n",
    "output_df = data_text[['name', 'description', 'tokens']]\n",
    "output_df.to_csv(\"data_recipe_features.csv\", index=False)\n",
    "print(\"✅ Fichier 'data_recipe_features.csv' sauvegardé avec succès !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-analysis-webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
